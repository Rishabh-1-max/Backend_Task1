{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "358152aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #A library for numerical computing (arrays, math functions, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53e0bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Library for data analysis & manipulation (DataFrames, tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92737e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  #Library for plotting graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93385f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Module for splitting datasets, cross-validation, etc. and Function that splits data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30bf48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Class to create a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa5f2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score #Measures how far predictions are from actual values.and Tools for measuring model accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f19e6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #Tools for preparing data before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a44b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline #Allows chaining multiple steps together (scaling + modeling) into one object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a38a21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None) #How many columns to show when printing a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d482baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 3) #How many decimals to show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a73fdf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"Housing_modified.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abf16068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH) #Pandas function to read CSV files into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a994367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (545, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape (rows, columns):\", df.shape) #A tuple (rows, columns) showing how many rows and columns your DataFrame has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d81453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guestroom</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>parking</th>\n",
       "      <th>area</th>\n",
       "      <th>furnishingstatus</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>basement</th>\n",
       "      <th>stories</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>5900</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4045214</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>6500</td>\n",
       "      <td>furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>6536696</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>4040</td>\n",
       "      <td>semi-furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3693404</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>semi-furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>6342007</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3960</td>\n",
       "      <td>furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>2765070</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>6673593</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5450</td>\n",
       "      <td>semi-furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>6137918</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>4500</td>\n",
       "      <td>furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4393705</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>4040</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3316448</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>5500</td>\n",
       "      <td>semi-furnished</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>6148997</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    guestroom hotwaterheating  parking  area furnishingstatus mainroad  \\\n",
       "0          no              no        1  5900      unfurnished       no   \n",
       "1          no              no        0  6500        furnished      yes   \n",
       "2          no              no        0  4040   semi-furnished      yes   \n",
       "3          no              no        0  5000   semi-furnished      yes   \n",
       "4          no              no        0  3960        furnished      yes   \n",
       "..        ...             ...      ...   ...              ...      ...   \n",
       "540        no              no        0  6000      unfurnished      yes   \n",
       "541        no              no        0  5450   semi-furnished      yes   \n",
       "542        no             yes        1  4500        furnished      yes   \n",
       "543        no              no        0  4040      unfurnished      yes   \n",
       "544       yes              no        1  5500   semi-furnished      yes   \n",
       "\n",
       "    airconditioning  bathrooms    price basement  stories prefarea  bedrooms  \n",
       "0                no          2  4045214      yes        2       no         4  \n",
       "1               yes          2  6536696       no        3      yes         3  \n",
       "2                no          1  3693404       no        1       no         2  \n",
       "3               yes          1  6342007       no        2       no         3  \n",
       "4                no          1  2765070       no        1       no         3  \n",
       "..              ...        ...      ...      ...      ...      ...       ...  \n",
       "540             yes          2  6673593       no        4       no         4  \n",
       "541             yes          2  6137918      yes        1      yes         4  \n",
       "542              no          2  4393705       no        3       no         3  \n",
       "543              no          1  3316448       no        1       no         2  \n",
       "544             yes          2  6148997       no        4       no         3  \n",
       "\n",
       "[545 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(545)) #Shows the 545 rows of the DataFrame to preview your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c36f411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "guestroom           object\n",
       "hotwaterheating     object\n",
       "parking              int64\n",
       "area                 int64\n",
       "furnishingstatus    object\n",
       "mainroad            object\n",
       "airconditioning     object\n",
       "bathrooms            int64\n",
       "price                int64\n",
       "basement            object\n",
       "stories              int64\n",
       "prefarea            object\n",
       "bedrooms             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nData types:\") \n",
    "display(df.dtypes) #df.dtypes â†’ Lists the data type (int64, float64, object, etc.) of each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924d1af",
   "metadata": {},
   "source": [
    "Code Part\tWhy Itâ€™s Used\n",
    "DATA_PATH\tStores the dataset location in one place for easy changes.\n",
    "pd.read_csv()\tLoads CSV data into pandas DataFrame.\n",
    "df.shape\tChecks dataset size quickly.\n",
    "df.head()\tPeeks at the first few rows to understand structure.\n",
    "df.dtypes\tShows what type of data each column has.\n",
    "df.isna().sum()\tFinds missing values in each column.\n",
    "display()\tMakes output tables look clean in notebooks.\n",
    "print()\tAdds clear labels to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2188cd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "guestroom           0\n",
       "hotwaterheating     0\n",
       "parking             0\n",
       "area                0\n",
       "furnishingstatus    0\n",
       "mainroad            0\n",
       "airconditioning     0\n",
       "bathrooms           0\n",
       "price               0\n",
       "basement            0\n",
       "stories             0\n",
       "prefarea            0\n",
       "bedrooms            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nMissing values per column:\") #\\n adds spacing in output.\n",
    "display(df.isna().sum())  #Returns a DataFrame of True/False values showing where data is missing and Counts the number of True values per column (i.e., number of missing entries).\n",
    "#Finds missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fff15916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df.copy() #Prevents modifying the original data accidentally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c89178ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "yn_cols = [\"mainroad\", \"guestroom\", \"basement\", \"hotwaterheating\", \"airconditioning\", \"prefarea\"] #yn_cols â†’ A list of column names that contain \"Yes\"/\"No\" values.\n",
    "\n",
    "#Example: if \"mainroad\" = \"Yes\", convert to 1; \"No\" â†’ 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2081923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_yes_no(series):  # Handle spaces/case safely: \" Yes \" -> \"yes\"\n",
    "     return series.astype(str).str.strip().str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "# '''map_yes_no(series) â†’ Converts \"Yes\"/\"No\" text in a Series (column) into 1/0.\n",
    "\n",
    "# series.astype(str) â†’ Ensures the column is treated as strings.\n",
    "\n",
    "# .str.strip() â†’ Removes extra spaces (\" Yes \" â†’ \"Yes\").\n",
    "\n",
    "# .str.lower() â†’ Converts everything to lowercase (\"YES\" â†’ \"yes\").\n",
    "\n",
    "# .map({\"yes\": 1, \"no\": 0}) â†’ Maps \"yes\" â†’ 1, \"no\" â†’'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d52b62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in yn_cols:\n",
    "    df_proc[c] = map_yes_no(df_proc[c]) \n",
    "#     for c in yn_cols: â†’ Loop through each Yes/No column.\n",
    "\n",
    "# df_proc[c] = ... â†’ Replace that column in the dataframe.\n",
    "\n",
    "# map_yes_no(df_proc[c]) â†’ Apply the conversion function to each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47246719",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3713095338.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython analyze_logs.py logfile\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "CC Timetable Generator â€” Log Analysis (one-file script)\n",
    "\n",
    "What it computes:\n",
    "- Total API requests served (by scanning lines containing HTTP method GET/POST)\n",
    "- Endpoint popularity (path counts)\n",
    "- Performance metrics per endpoint: average, max, and p95 response time\n",
    "- Users: unique IDs and per-year counts (year inferred from user ID tokens)\n",
    "- Timetable generation insights:\n",
    "  - Total timetables generated\n",
    "  - Average timetables generated per hour (if timestamps span can be computed)\n",
    "  - Algorithm usage counts (Backtracking vs Iterative random sampling)\n",
    "\n",
    "Extras:\n",
    "- Global success/error rates\n",
    "- Per-endpoint success/error rates\n",
    "- Requests per hour (if timestamps exist)\n",
    "\n",
    "Assumptions / Robustness:\n",
    "- Handles log lines where fields may appear in any order.\n",
    "- Extracts endpoint from request like \"GET /api/generate?x=1 HTTP/1.1\" -> \"/api/generate\"\n",
    "- Response time picked from common patterns (response_time=123ms, time=85ms, duration=0.12s, \"123ms\", etc.)\n",
    "- User IDs from tokens like user=2021ABC123, uid:19BCE1234, user_id=2022-xyzâ€¦, etc.\n",
    "- Year inferred as the first 4-digit number in 2010â€“2035 found within a captured user ID token.\n",
    "- Timestamps parsed from typical patterns (e.g., \"2025-08-20 10:15:23\", \"[2025-08-20 10:15:23,456]\", ISO8601).\n",
    "\n",
    "Usage:\n",
    "    python analyze_logs.py logfile.txt\n",
    "    python analyze_logs.py logfile.txt --out report.md\n",
    "\n",
    "If you have multiple files:\n",
    "    python analyze_logs.py logs/*.log --out combined_report.md\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "import statistics\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# Regex patterns (liberal)\n",
    "# -----------------------------\n",
    "\n",
    "# HTTP method + path + optional status\n",
    "METHOD_RE = re.compile(r'\\b(?P<method>GET|POST)\\b', re.IGNORECASE)\n",
    "\n",
    "# Try to extract request target like `GET /path?query ...` => group 'path'\n",
    "REQUEST_LINE_RE = re.compile(\n",
    "    r'\\b(?:GET|POST)\\s+(?P<path>/[^\\s\\?\"]+)', re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Status code: often 200, 400 etc. Allow 3-digit at word boundary.\n",
    "STATUS_RE = re.compile(r'\\b(?P<status>\\d{3})\\b')\n",
    "\n",
    "# Response time patterns (labelled preferred):\n",
    "# e.g., response_time=123ms, time: 85ms, duration=0.12s, rt=250ms\n",
    "LABELLED_TIME_RE = re.compile(\n",
    "    r'\\b(?:response[_\\- ]?time|duration|latency|time|rt)\\s*[:=]\\s*(?P<num>\\d+(?:\\.\\d+)?)\\s*(?P<Unit>ms|s)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Unlabelled \"123ms\" fallback (avoid matching timestamps by requiring ms/s)\n",
    "UNLABELLED_TIME_RE = re.compile(\n",
    "    r'\\b(?P<num>\\d+(?:\\.\\d+)?)\\s*(?P<Unit>ms|s)\\b'\n",
    ")\n",
    "\n",
    "# User identifiers: try common keys\n",
    "USER_TOKEN_RE = re.compile(\n",
    "    r'\\b(?:user(?:_id)?|uid|id)\\s*[:=]\\s*(?P<uid>[A-Za-z0-9_\\-:/\\.]+)',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# A 4-digit year embedded in a UID (common campus years)\n",
    "YEAR_IN_UID_RE = re.compile(r'\\b(20(1\\d|2\\d|3[0-5]))\\b')\n",
    "\n",
    "# Timetable generation lines and algorithm names\n",
    "# We count a line as \"timetable generated\" if it contains \"timetable\" + \"generat\"\n",
    "TIMETABLE_LINE_RE = re.compile(r'\\btime[\\w\\- ]*table\\b.*\\bgenerat', re.IGNORECASE)\n",
    "ALGO_BACKTRACK_RE = re.compile(r'\\bbacktracking\\b', re.IGNORECASE)\n",
    "ALGO_ITERATIVE_RE = re.compile(r'\\biterative\\s+random\\s+sampling\\b|\\biterative\\b', re.IGNORECASE)\n",
    "\n",
    "# Timestamp patterns (try a few common ones)\n",
    "TS_PATTERNS = [\n",
    "    # [2025-08-20 10:15:23,456]\n",
    "    r'\\[(?P<ts>\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}(?:,\\d{3})?)\\]',\n",
    "    # 2025-08-20 10:15:23 or 2025-08-20T10:15:23\n",
    "    r'(?P<ts>\\d{4}-\\d{2}-\\d{2}[ T]\\d{2}:\\d{2}:\\d{2}(?:\\.\\d{3,6})?)',\n",
    "    # 20/08/2025 10:15:23\n",
    "    r'(?P<ts>\\d{2}/\\d{2}/\\d{4}\\s+\\d{2}:\\d{2}:\\d{2})',\n",
    "]\n",
    "TS_RES = [re.compile(p) for p in TS_PATTERNS]\n",
    "\n",
    "def parse_ts(s):\n",
    "    for rx in TS_RES:\n",
    "        m = rx.search(s)\n",
    "        if not m:\n",
    "            continue\n",
    "        ts = m.group('ts')\n",
    "        # Try multiple datetime formats\n",
    "        for fmt in (\n",
    "            \"%Y-%m-%d %H:%M:%S,%f\",\n",
    "            \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "            \"%Y-%m-%dT%H:%M:%S.%f\",\n",
    "            \"%Y-%m-%dT%H:%M:%S\",\n",
    "            \"%d/%m/%Y %H:%M:%S\",\n",
    "        ):\n",
    "            try:\n",
    "                return datetime.strptime(ts, fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def ms_from_match(num_str, unit_str):\n",
    "    val = float(num_str)\n",
    "    unit = unit_str.lower()\n",
    "    if unit == 'ms':\n",
    "        return val\n",
    "    if unit == 's':\n",
    "        return val * 1000.0\n",
    "    return None\n",
    "\n",
    "def extract_latency_ms(line):\n",
    "    # Prefer labelled matches\n",
    "    m = LABELLED_TIME_RE.search(line)\n",
    "    if m:\n",
    "        return ms_from_match(m.group('num'), m.group('Unit'))\n",
    "    # Fallback to unlabelled \"123ms\" (but try not to pick up timestamps)\n",
    "    # We'll choose the smallest value that looks like a latency, to avoid e.g., a larger unrelated seconds value.\n",
    "    candidates = []\n",
    "    for m in UNLABELLED_TIME_RE.finditer(line):\n",
    "        ms = ms_from_match(m.group('num'), m.group('Unit'))\n",
    "        if ms is not None:\n",
    "            candidates.append(ms)\n",
    "    if candidates:\n",
    "        return min(candidates)\n",
    "    return None\n",
    "\n",
    "def extract_endpoint(line):\n",
    "    m = REQUEST_LINE_RE.search(line)\n",
    "    if not m:\n",
    "        return None\n",
    "    path = m.group('path')\n",
    "    # normalize: strip trailing slashes (except root)\n",
    "    if len(path) > 1 and path.endswith('/'):\n",
    "        path = path[:-1]\n",
    "    return path\n",
    "\n",
    "def extract_method(line):\n",
    "    m = METHOD_RE.search(line)\n",
    "    return m.group('method').upper() if m else None\n",
    "\n",
    "def extract_status(line):\n",
    "    # status can appear multiple times; prefer a 3xx/4xx/5xx/2xx near end, but keep it simple\n",
    "    # We'll take the last 3-digit number in the line as a heuristic.\n",
    "    statuses = [int(m.group('status')) for m in STATUS_RE.finditer(line)]\n",
    "    if not statuses:\n",
    "        return None\n",
    "    return statuses[-1]\n",
    "\n",
    "def extract_user_id_and_year(line):\n",
    "    uid = None\n",
    "    year = None\n",
    "    m = USER_TOKEN_RE.search(line)\n",
    "    if m:\n",
    "        uid = m.group('uid')\n",
    "        y = YEAR_IN_UID_RE.search(uid)\n",
    "        if y:\n",
    "            year = int(y.group(1))\n",
    "    else:\n",
    "        # Fallback: if we see a token that looks like a year elsewhere in the line, but only use it if\n",
    "        # there's also a word \"user\" nearby to avoid miscounting.\n",
    "        if re.search(r'\\buser\\b', line, re.IGNORECASE):\n",
    "            y = YEAR_IN_UID_RE.search(line)\n",
    "            if y:\n",
    "                year = int(y.group(1))\n",
    "    return uid, year\n",
    "\n",
    "def human_ms(ms):\n",
    "    if ms is None:\n",
    "        return \"n/a\"\n",
    "    if ms >= 1000:\n",
    "        return f\"{ms/1000:.2f}s\"\n",
    "    return f\"{ms:.0f}ms\"\n",
    "\n",
    "def p95(values):\n",
    "    if not values:\n",
    "        return None\n",
    "    v = sorted(values)\n",
    "    # 95th percentile (nearest-rank method)\n",
    "    idx = max(0, int(round(0.95 * (len(v) - 1))))\n",
    "    return v[idx]\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Analyze CC Timetable Generator logs and produce a Markdown report.\")\n",
    "    ap.add_argument(\"files\", nargs=\"+\", help=\"Path(s) to log file(s)\")\n",
    "    ap.add_argument(\"--out\", help=\"Optional path to write Markdown report\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    total_requests = 0\n",
    "    global_status = Counter()\n",
    "    endpoints = defaultdict(lambda: {\n",
    "        \"count\": 0,\n",
    "        \"latencies\": [],\n",
    "        \"status\": Counter(),\n",
    "        \"methods\": Counter(),\n",
    "    })\n",
    "\n",
    "    users_unique = set()\n",
    "    year_counts = Counter()\n",
    "\n",
    "    tt_total = 0\n",
    "    algo_counts = Counter()\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    for path in args.files:\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "                for line in f:\n",
    "                    # Timestamp\n",
    "                    ts = parse_ts(line)\n",
    "                    if ts:\n",
    "                        timestamps.append(ts)\n",
    "\n",
    "                    # Request-level parsing\n",
    "                    method = extract_method(line)\n",
    "                    endpoint = extract_endpoint(line)\n",
    "                    status = extract_status(line)\n",
    "                    latency = extract_latency_ms(line)\n",
    "\n",
    "                    if method and endpoint:\n",
    "                        total_requests += 1\n",
    "                        endpoints[endpoint][\"count\"] += 1\n",
    "                        endpoints[endpoint][\"methods\"][method] += 1\n",
    "                        if latency is not None:\n",
    "                            endpoints[endpoint][\"latencies\"].append(latency)\n",
    "                        if status is not None:\n",
    "                            endpoints[endpoint][\"status\"][status] += 1\n",
    "                            global_status[status] += 1\n",
    "\n",
    "                    # Users\n",
    "                    uid, year = extract_user_id_and_year(line)\n",
    "                    if uid:\n",
    "                        users_unique.add(uid)\n",
    "                    if year:\n",
    "                        year_counts[year] += 1\n",
    "\n",
    "                    # Timetable generation lines & algorithms\n",
    "                    if TIMETABLE_LINE_RE.search(line):\n",
    "                        tt_total += 1\n",
    "                    if ALGO_BACKTRACK_RE.search(line):\n",
    "                        algo_counts[\"Backtracking\"] += 1\n",
    "                    if ALGO_ITERATIVE_RE.search(line):\n",
    "                        algo_counts[\"Iterative random sampling\"] += 1\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[WARN] File not found: {path}\", file=sys.stderr)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Error reading {path}: {e}\", file=sys.stderr)\n",
    "\n",
    "    # Compute time span (for rates)\n",
    "    rate_note = \"\"\n",
    "    avg_tt_per_hour = None\n",
    "    reqs_per_hour = None\n",
    "    if timestamps:\n",
    "        tmin = min(timestamps)\n",
    "        tmax = max(timestamps)\n",
    "        elapsed_sec = max(1, (tmax - tmin).total_seconds())\n",
    "        hours = elapsed_sec / 3600.0\n",
    "        if hours > 0:\n",
    "            avg_tt_per_hour = tt_total / hours\n",
    "            reqs_per_hour = total_requests / hours\n",
    "            rate_note = f\"(from {tmin} to {tmax}, ~{hours:.2f}h span)\"\n",
    "    # Prepare report\n",
    "    lines = []\n",
    "    lines.append(\"# CC Timetable Generator â€” Log Report\")\n",
    "    if rate_note:\n",
    "        lines.append(f\"_Time window detected: {rate_note}_\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Total API requests\n",
    "    lines.append(\"## Total API requests served\")\n",
    "    lines.append(f\"- **Total**: {total_requests}\")\n",
    "    if global_status:\n",
    "        successes = sum(c for s, c in global_status.items() if 200 <= s < 300)\n",
    "        client_err = sum(c for s, c in global_status.items() if 400 <= s < 500)\n",
    "        server_err = sum(c for s, c in global_status.items() if 500 <= s < 600)\n",
    "        lines.append(f\"- **Success (2xx)**: {successes}\")\n",
    "        lines.append(f\"- **Client errors (4xx)**: {client_err}\")\n",
    "        lines.append(f\"- **Server errors (5xx)**: {server_err}\")\n",
    "        if total_requests:\n",
    "            err_rate = (client_err + server_err) * 100.0 / total_requests\n",
    "            lines.append(f\"- **Error rate**: {err_rate:.2f}%\")\n",
    "    if reqs_per_hour is not None:\n",
    "        lines.append(f\"- **Requests/hour**: {reqs_per_hour:.2f}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Endpoint popularity & performance\n",
    "    lines.append(\"## Endpoint Popularity & Performance\")\n",
    "    if not endpoints:\n",
    "        lines.append(\"_No endpoints detected (check log format or patterns)._\")\n",
    "    else:\n",
    "        # Sort by count desc\n",
    "        for ep, data in sorted(endpoints.items(), key=lambda kv: kv[1][\"count\"], reverse=True):\n",
    "            cnt = data[\"count\"]\n",
    "            methods = \", \".join(f\"{m}:{c}\" for m,c in sorted(data[\"methods\"].items()))\n",
    "            # Latency\n",
    "            lat = data[\"latencies\"]\n",
    "            avg_ms = statistics.mean(lat) if lat else None\n",
    "            max_ms = max(lat) if lat else None\n",
    "            p95_ms = p95(lat) if lat else None\n",
    "            # Status mix\n",
    "            s_ok = sum(c for s,c in data[\"status\"].items() if 200 <= s < 300)\n",
    "            s_4 = sum(c for s,c in data[\"status\"].items() if 400 <= s < 500)\n",
    "            s_5 = sum(c for s,c in data[\"status\"].items() if 500 <= s < 600)\n",
    "            lines.append(f\"### {ep}\")\n",
    "            lines.append(f\"- Requests: **{cnt}**\")\n",
    "            lines.append(f\"- Methods: {methods if methods else 'n/a'}\")\n",
    "            lines.append(f\"- Avg latency: {human_ms(avg_ms)}  |  Max: {human_ms(max_ms)}  |  P95: {human_ms(p95_ms)}\")\n",
    "            if (s_4 + s_5 + s_ok) > 0:\n",
    "                lines.append(f\"- Status mix: 2xx={s_ok}, 4xx={s_4}, 5xx={s_5}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "    # Users\n",
    "    lines.append(\"## Users\")\n",
    "    lines.append(f\"- **Unique users/IDs**: {len(users_unique)}\")\n",
    "    if year_counts:\n",
    "        lines.append(\"- **Users by year**:\")\n",
    "        for y, c in sorted(year_counts.items()):\n",
    "            lines.append(f\"  - {y}: {c}\")\n",
    "    else:\n",
    "        lines.append(\"_No year information detected in user IDs._\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Timetable generation insights\n",
    "    lines.append(\"## Timetable Generation Insights\")\n",
    "    lines.append(f\"- **Total timetables generated**: {tt_total}\")\n",
    "    if avg_tt_per_hour is not None:\n",
    "        lines.append(f\"- **Average timetables per hour**: {avg_tt_per_hour:.2f}\")\n",
    "    else:\n",
    "        lines.append(\"- **Average timetables per hour**: n/a (timestamps not found)\")\n",
    "    if algo_counts:\n",
    "        lines.append(\"- **Algorithm usage:**\")\n",
    "        for k,v in sorted(algo_counts.items(), key=lambda kv: kv[0]):\n",
    "            lines.append(f\"  - {k}: {v}\")\n",
    "    else:\n",
    "        lines.append(\"- **Algorithm usage:** n/a\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Nice extras summary\n",
    "    lines.append(\"## Additional Metrics\")\n",
    "    if reqs_per_hour is not None:\n",
    "        lines.append(f\"- Requests/hour: {reqs_per_hour:.2f}\")\n",
    "    # Top endpoints quick glance\n",
    "    if endpoints:\n",
    "        top_ep = max(endpoints.items(), key=lambda kv: kv[1][\"count\"])[0]\n",
    "        lines.append(f\"- Busiest endpoint: `{top_ep}`\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    report = \"\\n\".join(lines)\n",
    "\n",
    "    if args.out:\n",
    "        try:\n",
    "            with open(args.out, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(report)\n",
    "            print(f\"[OK] Report written to {args.out}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to write {args.out}: {e}\", file=sys.stderr)\n",
    "            print(report)\n",
    "    else:\n",
    "        print(report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
